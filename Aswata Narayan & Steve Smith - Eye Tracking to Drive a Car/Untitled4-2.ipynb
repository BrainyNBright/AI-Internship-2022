{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the requires libaries\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "import dlib\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:23:35.132282: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "#import the model we trained and saved in the other notebook\n",
    "new_model=tf.keras.models.load_model('eye_track.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-23 16:25:11.948006: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6826eb310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "center\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc682dd6280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "center\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc683108160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "center\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc692473c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "center\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc6b513e8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "center\n"
     ]
    }
   ],
   "source": [
    "#prepared the image so that it can be understood by the model\n",
    "def prepare(filepath):\n",
    "    img_array=cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
    "    new_array=cv2.resize(img_array,(400,600))\n",
    "    return new_array.reshape(-1,200,200,3)\n",
    "\n",
    "#turns on the webcam to capture the face\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "def midpoint(p1 ,p2):\n",
    "    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "    for face in faces:\n",
    "        \n",
    "        #draws green lines across the eyes to identify them\n",
    "        landmarks = predictor(gray, face)\n",
    "        Lleft_point = (landmarks.part(36).x, landmarks.part(36).y)\n",
    "        Lright_point = (landmarks.part(39).x, landmarks.part(39).y)\n",
    "        Lcenter_top = midpoint(landmarks.part(37), landmarks.part(38))\n",
    "        Lcenter_bottom = midpoint(landmarks.part(41), landmarks.part(40))\n",
    "\n",
    "        horL_line = cv2.line(frame, Lleft_point, Lright_point, (0, 255, 0), 2)\n",
    "        verL_line = cv2.line(frame, Lcenter_top, Lcenter_bottom, (0, 255, 0), 2)\n",
    "        \n",
    "        Rleft_point = (landmarks.part(42).x, landmarks.part(42).y)\n",
    "        Rright_point = (landmarks.part(45).x, landmarks.part(45).y)\n",
    "        Rcenter_top = midpoint(landmarks.part(43), landmarks.part(44))\n",
    "        Rcenter_bottom = midpoint(landmarks.part(47), landmarks.part(46))\n",
    "\n",
    "        horR_line = cv2.line(frame, Rleft_point, Rright_point, (0, 255, 0), 2)\n",
    "        verR_line = cv2.line(frame, Rcenter_top, Rcenter_bottom, (0, 255, 0), 2)\n",
    "        \n",
    "        #draws a rectangle around the eyes so that it can be easily cropped and prepared for the model to understand\n",
    "        x=(landmarks.part(17).x,landmarks.part(17).y)\n",
    "        y=(landmarks.part(15).x,landmarks.part(15).y)\n",
    "        x1=(landmarks.part(26).x,landmarks.part(26).y)\n",
    "        y1=(landmarks.part(1).x,landmarks.part(1).y)\n",
    "        rectangle=cv2.rectangle(frame, x, y, (255,0,0), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == ord('w'):\n",
    "        #takes a picture of the frame\n",
    "        cv2.imwrite('pic.png',frame)\n",
    "        img=cv2.imread('pic.png')\n",
    "        #crops the frame so only the eyes are visible\n",
    "        cropped_image=img[x[1]:y[1],x[0]:y[0]]\n",
    "        cv2.imwrite(\"cropped.jpg\", cropped_image)\n",
    "\n",
    "        categories=['center','right','down','up','left']\n",
    "        \n",
    "        renew=prepare('cropped.jpg')\n",
    "        \n",
    "        #feeds the prepared image to the model so that it can identify it\n",
    "        new_model=tf.keras.models.load_model('eye_track.h5')\n",
    "        prediction=new_model.predict([renew])\n",
    "        print(categories[int(prediction[0][0])])\n",
    "\n",
    "    #destroys the window when esc key is pressed\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
