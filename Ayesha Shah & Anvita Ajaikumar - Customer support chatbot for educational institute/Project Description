1. What is the problem?

    Educational institutes (schools, colleges, universities) often have an official website where parents and students would oftentimes visit with queries and/or
    complaints. Oftentimes the website may prove too difficult to navigate and/or confusing, otherwise the website would redirect the parents/students to a phone
    call with the school's receptionists. However, in the latter case, it adds more duties to the hands of the receptionists and makes it more difficult to answer
    numerous calls. Another problem is that parents and students may not want to call for various reasons. It may also be very inconvenient for studdents and
    parents to be put on hold when they call.
    
    
    
2. What is the solution?

    A probable solution could be the implementation of chatbots, especially in cases where the educational institution's administration is not available for
    students and parents 24/7. Utilizing a chatbot, in this scenario, would mean that students and parents will no longer have to wait on hold for human assistance.
    A chatbot can provide all relevant information on being asked a single question. Not only does it effectively eliminate the need for phone calls and any
    potential issue it may pose for students/parents (eg. not wanting to talk due to sore throat), it also decreases the responsibilities of receptionists.
    


3. How can ai be utilized to solve this problem?

    Predictive ai in conversation makes it much faster to respond, as well as being highly effective. It saves the institute's staff from having more work to do,
    as well as also effectively and fluently communicating with parents aand students. The ai can be utilized to provide professional and informative solutions to
    the problems of parents and students in constructive responses.
    


4. What are the different kinds of chatbots?

    There are rule-based and self-learning chatbots. Rule-based chatbots host a sequence of pre-determined rules on which it was initially trained in order to
    answer customer queries. Unfortunately, this approach is very limited and unable to answer more diverse queries. In direct contrast, the self-learning
    chatbot offers a variety of responses to different questions and can oftentimes provide better answers for more complicated queries/requests. The latter
    option is the one which we have decided to go with for this project, as it is more useful and diverse in answers.
    
    Self-learning bots can be further divided into two categories – retrieval-based or generative. 
    
    The retrieval-based chatbot functions on predefined input
    patterns and set responses. Once the question/pattern is entered, the chatbot uses a heuristic approach to deliver the appropriate response. The
    retrieval-based model is extensively used to design goal-oriented chatbots with customized features like the flow and tone of the bot to enhance the
    customer experience.
    
    Unlike retrieval-based chatbots, generative chatbots are not based on predefined responses – they leverage seq2seq neural networks (sequence to sequence
    is a special class of "Recurrent Neural Network" architectures that is typically used for solving complex language problems like Machine Translation,
    Question Answering, creating Chatbots, Text Summarization, etc.). This is based on the concept of machine translation where the source code is translated
    from one language to another language. In seq2seq approach, the input is transformed into an output.
    
    We came to the conclusion that a retrieval-based chatbot would be more suitable for an educational institute due to the fact that they tend to be more
    goal oriented and that they contain customized features like the flow and tone fo the bot.



6. What are some similar examples/projects of ai chatbots?

    find different projects related to chatbot. reference links



5. What is the methodology involved in creating this ai?

    ------------------------------------------------------------------------------------------------------------------------------------------------------------
    
    **Chatbot Types**
    
    After having collected to relevant data required in order to train and test the model, we now need to create it.
    
    To build a chatbot, we first require knowing the chatbot type that will act as the foundation from which the program can be coded.
    
    There are many chatbot type that we can choose from:

        A) Rule-based
        B) Self-learning
            i) Retrieval-based
            ii) Generative
    
    
    Rule-based:
    
        Rule-based chatbots host a sequence of pre-determined rules on which it was initially trained in order to answer customer queries. Unfortunately,
        this approach is very limited and unable to answer more diverse queries.
        
        
    Self-learning:
    
        A self-learning chatbot offers a variety of responses to different questions and can oftentimes provide better answers for more complicated
        queries/requests. This is significantly more relevant to the chatbot we would like to use, and so we will therefore be using a self-learning chatbot.
        However, this is also further divided into two more catagories.
        
        Retrieval-based:
        
            The retrieval-based chatbot functions on predefined inputs, patterns and set responses. Once the question/pattern is entered, the chatbot uses a
            heuristic approach to deliver the appropriate response. The retrieval-based model is extensively used to design goal-oriented chatbots with
            customized features like the flow and tone of the bot to enhance the customer experience.
        
        Generative:
            
            Generative chatbots are not based on predefined responses – they leverage seq2seq neural networks (sequence to sequence is a special class of
            "Recurrent Neural Network" architectures that is typically used for solving complex language problems like Machine Translation, Question Answering,
            creating Chatbots, Text Summarization, etc.). This is based on the concept of machine translation where the source code is translated from one
            language to another language. In seq2seq approach, the input is transformed into an output.
    
    Understanding that the purpose of this chatbot is for an educational institute, we have decided to go with a self-learning retrieval-based chatbot. This is
    because it offers a much wider variety of responses to different questions. It being retrieval-based also means we would be able to customize the fluency
    in which it responds, as well as the degree of formality and etc. 
    ------------------------------------------------------------------------------------------------------------------------------------------------------------
    
    **Program Platform**
    
    # write an assessment regarding multiple program platforms.
    
    # evaluate which platform would be most suitable for this project.
    
    ------------------------------------------------------------------------------------------------------------------------------------------------------------
    
    **Intent, Entity & Dialog**
    
    To properly understand and identify the method that will be most suitable for this project, we first have to figure out the user's intent, the entity, and
    the dialogue.
    
    Chatbots use natural language processing (NLP) to understand the user’s intent which means recognizing user’s aim in starting this conversation. Intent
    recognition is a critical feature that determines if a chatbot will succeed at fulfilling the user’s needs.
    
    The quantity of the chatbot’s training data is essential in order to maintain a good conversation with the user. However, the data quality determines the
    bot’s ability to detect the right intent and generate the correct response.
    
    There are generally 3 steps involved in intent classification:
        1. Data collection
        2. Preprocessing
        3. Morphological analysis
        4. Machine learning classifier selection and feature extraction
        5. Performance measure and comparison
        
    Natural language processing (NLP) allows the chatbot to understand the user’s message, and machine learning classification algorithms to classify this
    message based on the training data, and deliver the correct response. The steps required for the chatbot to have an informative conversation include:
        1. Preprocessing for Natural Language Understanding (NLU)
                NLU is a sub-catagory in NLP that focuses on organizing the user’s unstructured input such that the chatbot can understand and analyze it. This 
                process includes:
                        1. Syntax analysis
                                Identifying the basic grammar rules, word organization, combination and relation to one another. This consists of:
                                    - Splitting the text into smaller segments (words, shorter sentences) called "Tokens"
                                    - Labeling the tokens as noun, verb, adjective, etc. This step is called "Part of Speech" tagging (PoS)
                                    - Reducing words into their roots for better analysis
                                    - Filter out filling words to save space and time in processing large data
                        2. Semantic analysis
                                Inferring the meaning of the input sentence by:
                                    - Distinguishing the context of each word
                                    - Understanding the relationships between the words in the text
                NLU models utilize:
                    - Supervised machine learning for syntax analysis steps (tokenization, PoS tagging), such as support vector machines (SVM), Bayesian networks,
                      and maximum entropy algorithms.
                    - Unsupervised machine learning for semantic analysis such as clustering algorithms.
                    
        2. Chatbot Intent Classificcation
                Classifiers are trained on relevant labeled datasets, therefore this is a supervised learning application. Classifiers utilize:
                    - Rules based pattern matching
                    - Machine learning classification algorithms such as decision trees, naïve Bayes, and logistic regression.
                    - Deep learning such as artificial neural networks
                An intent classifier is used to match the output of the NLU process to relevant pre-defined labels in the training dataset. For example, when the
                user tells the chatbot: “I want to book a flight from Houston to LA”, the intent classifier will classify the context and sequence of words under
                the label “book flight”.
        
        3. Response Generation
                To generate responses, chatbots either rely on pre-defined recommendations or they could generate recommendations on the fly. For commercial
                applications, responses tend to be pre-defined to ensure that customers receive a consistent service and the bot does not respond in unintended
                ways.
                
                The dialog is formulated to achieve a specific goal, like acquiring the user’s information, providing suggestions about a product or a service,
                or directing the user to a live receptionist.
    
    Certain things, such as typos and spelling errors, may make it difficult for the chatbot to decipher the user's intent. After understanding various problems
    such as this, we will implement these solutions:
    - AI spell checking algorithms can be implemented with NLP models to autocorrect users’ misspellings and typos. For example, Google Docs’s autocorrect feature
      that points out misspellings, grammatical errors, and provides enhancements on text structure.
    - Lemmatization will make it easier for the chatbot to understand the user's queries.
    - Allowing users to create custom intents. For example in Amazon Alexa the user can set rules for the chatbot to perform a specific task by providing a name
      and a list of utterances that users would say to invoke this intent. [OPTIONAL]
    - Increasing the volume of training data will decrease the margin of error in intent detection.
    - Converting to lower case.
    - Tokenizing (splitting sentences into small decipherable words for the computer to understand) via NLTK's (Natural Language Toolkit) Tweettokenizer.
    - Filtering out stop-words (irrelvant additional vocabulary).
    - Removing punctuation and URL links.
    - Expanding contractions.
    - Removing emojis and numbers.
    - Limiting each message length to 50
      
    Now, we will move onto entity extraction.
    
    Entities are predefined categories of names, organizations, time expressions, quantities, and other general groups of objects that make sense. Using NLP,
    chatbots can extract entities from entries that users type in in order return around accurate recommendations and answers.
    
    Knowing the difference between intent and entity is critical to using chatbots for customer service. Intent implies what the customer is looking for, whereas
    entity is the specified field/data.
    
    Intent and entities in chatbots are both essential to delivering what the customer wants and needs.
    
    Due to the fact that this chatbot's purpose is regarding an educational institute, many of the specific necessary entities would be academically-related.
    
    After understanding intent and entity, it is necessary to find data that best covers as many scenarios that the customer might ask and that you want the chatbot
    to reply to as possible. The data should contain all the intents you want to be able to answer. It could come from multiple sources as long as they are within
    the same general domain.
    
    For each intent, we should have a sizable amount of examples so that the bot will be able to learn the nature of that intent.
    
    
    
    ------------------------------------------------------------------------------------------------------------------------------------------------------------
    
    **Steps Involved**
    
    After doing some research, we were able to come across NTLK (The Natural Language Toolkit, a suite of libraries and programs for symbolic and statistical
    natural language processing for English) and Keras (an open-source software library that provides a Python interface for artificial neural networks). They
    work well with AI and neural networks. With the research we have completed, we believe the proper methodology for creating this bot would be:
    
        1. install the library using
                conda install tensorflow
                conda install keras
                conda install pickle5
                conda install nltk
        2. import the classes using 
                import json
                import numpy as np
                import random
                import nltk
                import utils as u
                #nltk.download(‘punkt’)
                #nltk.download(‘wordnet’)
                from keras.models import Sequential
                from keras.layers import Dense, Activation, Dropout
                from keras.optimizers import SGD
        3. .
                #write soon.
