{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoCorrect",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGtUEwuCugLv",
        "outputId": "2a2034b1-d60d-404a-e075-6b928960ddce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pattern) (4.9.1)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20220524-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pattern) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pattern) (3.7)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 27.8 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 51.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pattern) (2.23.0)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.5.2-py3-none-any.whl (10 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from cherrypy->pattern) (8.13.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.1-py3-none-any.whl (7.3 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.1)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.8.1-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.2-py3-none-any.whl (6.0 kB)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.2-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.9.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (4.64.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->pattern) (1.1.0)\n",
            "Collecting cryptography>=36.0.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 43.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfminer.six->pattern) (2.1.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332721 sha256=015839998dc2b144607fba4a85907592af15493064f4fc87dd7f4d0ddf4c0649\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/1f/4e/9b67afd2430d55dee90bd57618dd7d899f1323e5852c465682\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp37-cp37m-linux_x86_64.whl size=99982 sha256=696b17ee5a2d3df23fb0b2dcfab37b0073d8740bf024c19e84169899368bcc10\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/2d/67/2cb3f82e435fc8e055cb2761a15a0812bf086068f6fb835462\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=5ae12027a0c45cbfae2ae50c717da291ed7862864af8416cb6980a66fe2f5456\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=d2c23928b4c6c0402b11554307655ef7ec2c334c4f745a619a7f9b8b78a82d1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: jaraco.functools, jaraco.context, tempora, jaraco.text, jaraco.classes, zc.lockfile, sgmllib3k, portend, jaraco.collections, cryptography, cheroot, python-docx, pdfminer.six, mysqlclient, feedparser, cherrypy, backports.csv, pattern\n",
            "Successfully installed backports.csv-1.0.7 cheroot-8.6.0 cherrypy-18.8.0 cryptography-37.0.4 feedparser-6.0.10 jaraco.classes-3.2.2 jaraco.collections-3.5.2 jaraco.context-4.1.2 jaraco.functools-3.5.1 jaraco.text-3.8.1 mysqlclient-2.1.1 pattern-3.6 pdfminer.six-20220524 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.0.2 zc.lockfile-2.0\n"
          ]
        }
      ],
      "source": [
        "pip install pattern"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kUgsfYbG6XBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspellchecker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UKBJVHMuqvf",
        "outputId": "d4c76c52-5c72-4fd1-db43-425f56bdbb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 5.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autocorrect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Gn-DZ5fu5Z9",
        "outputId": "4f6ed6c9-fab4-4610-bb64-c65597b4be90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[K     |████████████████████████████████| 622 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=c0390fed77ff5af0bf864ae028f926fe16e1ed1e8d3da5a777f3f2e485aa8939\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEt79JOEvAjr",
        "outputId": "49eb1689-1658-4c77-9082-b8cd69c87646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textdistance "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1BBNa7Eva_t",
        "outputId": "21c95999-8aae-4c56-e9d4-099de13c39e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textdistance\n",
            "  Downloading textdistance-4.3.0-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: textdistance\n",
            "Successfully installed textdistance-4.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Data Preprocessing\n",
        "import re  # regular expression\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Implement the function process_data which\n",
        "# 1) Reads in a corpus\n",
        "# 2) Changes everything to lowercase\n",
        "# 3) Returns a list of words.\n",
        "\n",
        "w = [] #words\n",
        "with open('sample.txt','r',encoding=\"utf8\") as f:\n",
        "    file_name_data = f.read()\n",
        "    file_name_data = file_name_data.lower()\n",
        "    w = re.findall('\\w+', file_name_data)\n",
        "\n",
        "v = set(w) #vocabulary\n",
        "print(f\"The first 10 words in our dictionary are: \\n{w[0:10]}\")\n",
        "print(f\"The dictionary has {len(v)} words \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu_jHrQdvhLi",
        "outputId": "8dfe4478-855d-4803-85f4-764cf388ab5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 words in our dictionary are: \n",
            "['a', 'ability', 'able', 'about', 'above', 'accept', 'according', 'account', 'across', 'act']\n",
            "The dictionary has 1001 words \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Implement the function process_data \n",
        "def get_count(words):\n",
        "    word_count_dict = {}\n",
        "    for word in words:\n",
        "        if word in word_count_dict:\n",
        "            word_count_dict[word] += 1\n",
        "        else:\n",
        "            word_count_dict[word] = 1\n",
        "    return word_count_dict\n",
        "word_count_dict = get_count(w)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcrh9CXpuinf",
        "outputId": "2a13a3d8-5d79-49a3-c560-1fcf0d89a93a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1001 key values pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_count = get_count(w)\n",
        "print(f\"The dictionary has  {len(word_count)} key values pairs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2D0IRLt4f9Q",
        "outputId": "5b69696b-7a82-4a47-bcc4-f27936ed5354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dictionary has  1001 key values pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implement get_probs function\n",
        "# to calculate the probability that any word will appear if randomly selected from the dictionary\n",
        "\n",
        "def get_probs(word_count_dict):\n",
        "    probs = {}\n",
        "    m = sum(word_count_dict.values())\n",
        "    for key in word_count_dict.keys():\n",
        "        probs[key] = word_count_dict[key] / m\n",
        "    return probs\n"
      ],
      "metadata": {
        "id": "MInks-dWzfGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we implement 4 edit word functions\n",
        "\n",
        "# DeleteLetter:removes a letter from a given word\n",
        "def DeleteLetter(word):\n",
        "    delete_list = []\n",
        "    split_list = []\n",
        "    for i in range(len(word)):\n",
        "        split_list.append((word[0:i], word[i:]))\n",
        "    for a, b in split_list:\n",
        "        delete_list.append(a + b[1:])\n",
        "    return delete_list\n",
        "\n",
        "delete_word_l = DeleteLetter(word=\"cans\")"
      ],
      "metadata": {
        "id": "3l_s0YG5zn_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DeleteLetter(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUx5R1_tz_Xm",
        "outputId": "840358d1-bc88-4a3a-b06a-5a64fefcb09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rash', 'tash', 'trsh', 'trah', 'tras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SwitchLetter:swap two adjacent letters\n",
        "def SwitchLetter(word):\n",
        "    split_l = []\n",
        "    switch_l = []\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_l if len(b) >= 2]\n",
        "    return switch_l\n",
        "\n",
        "switch_word_l = SwitchLetter(word=\"eta\")"
      ],
      "metadata": {
        "id": "Irm3pci50SzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(SwitchLetter(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH2JJibM0ZZc",
        "outputId": "873460aa-85f1-49f4-e985-8db728e4ca85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rtash', 'tarsh', 'trsah', 'trahs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace_letter: changes one letter to another\n",
        "def replace_letter(word):\n",
        "    split_l = []\n",
        "    replace_list = []\n",
        "    for i in range(len(word)):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    replace_list = [a + l + (b[1:] if len(b) > 1 else '') for a, b in split_l if b for l in alphabets]\n",
        "    return replace_list\n",
        "\n",
        "replace_l = replace_letter(word='can')"
      ],
      "metadata": {
        "id": "UhQSDvwk0n4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(replace_letter(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EsgxFuq0zdb",
        "outputId": "3bf0fc5c-6170-416f-f6d3-2f8c1bc8e46a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arash', 'brash', 'crash', 'drash', 'erash', 'frash', 'grash', 'hrash', 'irash', 'jrash', 'krash', 'lrash', 'mrash', 'nrash', 'orash', 'prash', 'qrash', 'rrash', 'srash', 'trash', 'urash', 'vrash', 'wrash', 'xrash', 'yrash', 'zrash', 'taash', 'tbash', 'tcash', 'tdash', 'teash', 'tfash', 'tgash', 'thash', 'tiash', 'tjash', 'tkash', 'tlash', 'tmash', 'tnash', 'toash', 'tpash', 'tqash', 'trash', 'tsash', 'ttash', 'tuash', 'tvash', 'twash', 'txash', 'tyash', 'tzash', 'trash', 'trbsh', 'trcsh', 'trdsh', 'tresh', 'trfsh', 'trgsh', 'trhsh', 'trish', 'trjsh', 'trksh', 'trlsh', 'trmsh', 'trnsh', 'trosh', 'trpsh', 'trqsh', 'trrsh', 'trssh', 'trtsh', 'trush', 'trvsh', 'trwsh', 'trxsh', 'trysh', 'trzsh', 'traah', 'trabh', 'trach', 'tradh', 'traeh', 'trafh', 'tragh', 'trahh', 'traih', 'trajh', 'trakh', 'tralh', 'tramh', 'tranh', 'traoh', 'traph', 'traqh', 'trarh', 'trash', 'trath', 'trauh', 'travh', 'trawh', 'traxh', 'trayh', 'trazh', 'trasa', 'trasb', 'trasc', 'trasd', 'trase', 'trasf', 'trasg', 'trash', 'trasi', 'trasj', 'trask', 'trasl', 'trasm', 'trasn', 'traso', 'trasp', 'trasq', 'trasr', 'trass', 'trast', 'trasu', 'trasv', 'trasw', 'trasx', 'trasy', 'trasz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insert_letter: adds additional characters\n",
        "def insert_letter(word):\n",
        "    split_l = []\n",
        "    insert_list = []\n",
        "    for i in range(len(word) + 1):\n",
        "        split_l.append((word[0:i], word[i:]))\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_list = [a + l + b for a, b in split_l for l in letters]\n",
        "    # print(split_l)\n",
        "    return insert_list"
      ],
      "metadata": {
        "id": "fTprBYl60-0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(insert_letter(\"trash\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wHyU0gz1BcX",
        "outputId": "e462377a-9fa1-48cf-c0ff-6a8167bc4636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atrash', 'btrash', 'ctrash', 'dtrash', 'etrash', 'ftrash', 'gtrash', 'htrash', 'itrash', 'jtrash', 'ktrash', 'ltrash', 'mtrash', 'ntrash', 'otrash', 'ptrash', 'qtrash', 'rtrash', 'strash', 'ttrash', 'utrash', 'vtrash', 'wtrash', 'xtrash', 'ytrash', 'ztrash', 'tarash', 'tbrash', 'tcrash', 'tdrash', 'terash', 'tfrash', 'tgrash', 'thrash', 'tirash', 'tjrash', 'tkrash', 'tlrash', 'tmrash', 'tnrash', 'torash', 'tprash', 'tqrash', 'trrash', 'tsrash', 'ttrash', 'turash', 'tvrash', 'twrash', 'txrash', 'tyrash', 'tzrash', 'traash', 'trbash', 'trcash', 'trdash', 'treash', 'trfash', 'trgash', 'trhash', 'triash', 'trjash', 'trkash', 'trlash', 'trmash', 'trnash', 'troash', 'trpash', 'trqash', 'trrash', 'trsash', 'trtash', 'truash', 'trvash', 'trwash', 'trxash', 'tryash', 'trzash', 'traash', 'trabsh', 'tracsh', 'tradsh', 'traesh', 'trafsh', 'tragsh', 'trahsh', 'traish', 'trajsh', 'traksh', 'tralsh', 'tramsh', 'transh', 'traosh', 'trapsh', 'traqsh', 'trarsh', 'trassh', 'tratsh', 'traush', 'travsh', 'trawsh', 'traxsh', 'traysh', 'trazsh', 'trasah', 'trasbh', 'trasch', 'trasdh', 'traseh', 'trasfh', 'trasgh', 'trashh', 'trasih', 'trasjh', 'traskh', 'traslh', 'trasmh', 'trasnh', 'trasoh', 'trasph', 'trasqh', 'trasrh', 'trassh', 'trasth', 'trasuh', 'trasvh', 'traswh', 'trasxh', 'trasyh', 'traszh', 'trasha', 'trashb', 'trashc', 'trashd', 'trashe', 'trashf', 'trashg', 'trashh', 'trashi', 'trashj', 'trashk', 'trashl', 'trashm', 'trashn', 'trasho', 'trashp', 'trashq', 'trashr', 'trashs', 'trasht', 'trashu', 'trashv', 'trashw', 'trashx', 'trashy', 'trashz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combining the edits\n",
        "# switch operation optional\n",
        "def edit_one_letter(word, allow_switches=True):\n",
        "    edit_set1 = set()\n",
        "    edit_set1.update(DeleteLetter(word))\n",
        "    if allow_switches:\n",
        "        edit_set1.update(SwitchLetter(word))\n",
        "    edit_set1.update(replace_letter(word))\n",
        "    edit_set1.update(insert_letter(word))\n",
        "    return edit_set1\n",
        "\n",
        "# edit two letters\n",
        "def edit_two_letters(word, allow_switches=True):\n",
        "    edit_set2 = set()\n",
        "    edit_one = edit_one_letter(word, allow_switches=allow_switches)\n",
        "    for w in edit_one:\n",
        "        if w:\n",
        "            edit_two = edit_one_letter(w, allow_switches=allow_switches)\n",
        "            edit_set2.update(edit_two)\n",
        "    return edit_set2\n",
        "\n",
        "# get corrected word\n",
        "def get_corrections(word, probs, vocab, n=2):\n",
        "    suggested_word = []\n",
        "    best_suggestion = []\n",
        "    suggested_word = list(\n",
        "        (word in vocab and word) or edit_one_letter(word).intersection(vocab) or edit_two_letters(word).intersection(\n",
        "            vocab))\n",
        "    best_suggestion = [[s, probs[s]] for s in list(reversed(suggested_word))]\n",
        "    return best_suggestion\n",
        "\n",
        "my_word = input(\"Enter any word:\")\n",
        "probs = get_probs(word_count)\n",
        "tmp_corrections = get_corrections(my_word, probs, v, 2)\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV5itmOU2Ir7",
        "outputId": "7cfcf37c-18b0-46f4-b248-170282b18431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter any word:arond\n",
            "word 0: around, probability 0.000999\n"
          ]
        }
      ]
    }
  ]
}