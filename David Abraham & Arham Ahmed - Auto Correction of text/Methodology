



Methodology:


Up till now most of our work included gathering the necessary data required to train and test our model.


It's time to integrate this data into a working machine model.


In order to develop the autocorrection model, an algorithm that lays the groundwork for the infrastructure of the coded program is required.




Next, we import all the necessary libraries and packages to read the text file containing a vocabulary dictionary.



At this step, we require the model that is capable of editing our particular string. To achieve this task, we will need to implement four functions 
in order to edit the string. 


Editing is an operation performed on the string to change it to another string.

One factor that enables us to perform crucial edits is "edit_distance" which is the parameter controlling the number of edit operations to be implemented.


Hence, the edit distance is the count of the number of operations performed on a string to edit it.


The following are examples of edits:


INSERT - Adds a letter.
DELETE - removes a letter.
SWAP - swaps two adjacent letters.
REPLACE - changes one letter to another.



Only correctly spelled words from the created candidate list are considered, so that we can compare them to the words in the corpus to filter out the ones 
that donâ€™t exist.


The probabilities of the words are calculated based on the following formula:

P(w) = C(w)/V

P(w)- the probability of a word w.

C(w) - number of times (frequency) word appears in the vocabulary dictionary.

V - the total sum of words in the dictionary.





When the probabilities are calculated, the actual list of words is grouped by the most likely word from the created candidates.


We will need a dictionary to develop an autocorrect system where the model uses history to match the typed words to see if they are correct or not.


To do this, we start by installing all the libraries general to machine learning from the terminal.




As we have seen, NLP plays a crucial role in enabling computers to understand and process natural human language. This is implemented above using the Autocorrect
system. By referring to these detailed steps, we are able to comprehend the role of NLP for the design and functioning of our 
Autocorrect Model. 





-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Steps:

In the following lines, we will demonstrate the fundamental foundation of the functioning of our algorithm and our procedures.




To begin, we would need to import the neccessary libraries:
 
- "Pandas"

- "Numpy"

- "sklearn"

- "GaussianNB"

- "pattern"

- "pyspellchecker"

- "autocorrect"

- "textblob"

- "textdistance"





After this, we obtian a suitable data set for our model. Through extensive research, we were able to come up with a file including 1001 of the most popular words 
used by individuals today. 


This set would be enough to provide a wide range of vocabulary.


Certain terms will need to be defined technically before we go into details about the code so as to fully comprehend it. 


get_count:

- A function that returns a dictionary of word versus frequency.



get_probs function:

- Used to calculate the probability that any word will appear if randomly selected from the dictionary.




Next we need to implement functions to edit our given word, these include four main functinons:


-'SwitchLetter' (Swaps to adajacent Character)

-'Replace_letter' (Replaces one Character for another)

-'Insert_Letter' (Adds additional Character)

-'Delete_Letter' (Deletes a character)



Then, we need to combine the functions and alow the Model to switch between the functions when required.




Our model functions by permitting two edits for a given string in order to create a string with a high probability of being the intended word. 

The function that enables us to perform these edits is called "edit_two_letters".


The program will prompt the user to input a word then will go through the dictionary and produce words similar to the input word.

For instance, when a user tries to type the word "attakk" to mean "attack". The autocorrect system produces a number of similar words like "attack" 
with a probability of 0.000999.



 







Completed :),


Arham
David
Heet























