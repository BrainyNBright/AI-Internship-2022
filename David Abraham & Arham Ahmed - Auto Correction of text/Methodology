



Methodology:


Up till now most of our work included gathering the necessary data required to train and test our model.


It's time to integrate this data into a working machine model.


In order to develop the autocorrection model, an algorithm that lays the groundwork for the infrastructure of the coded program is required.






To begin, we start by installing all the libraries general to machine learning from the terminal.


Next, we import all the necessary libraries and packages to read the text file containing a vocabulary dictionary



At this step, we require the model that is capable of editing our particular string. To achieve this task, we will need to implement four functions 
in order to edit the string. 


Editing is an operation performed on the string to change it to another string.

One factor that enables us to perform crucial edits is "edit_distance" which is the parameter controlling the number of edit operations to be implemented.


Hence, the edit distance is the count of the number of operations performed on a word to edit it.


The following are examples of edits:


INSERT - a letter should be added.
DELETE - removes a letter.
SWAP - swaps two adjacent letters.
REPLACE - changes one letter to another.



Only correctly spelled words from the created candidate list are considered, so that we can compare them to the words in the corpus to filter out the ones 
that donâ€™t exist.


The probabilities of the words are calculated based on the following formula:

P(w) = C(w)/V

P(w)- the probability of a word w.

C(w) - number of times (frequency) word appears in the vocabulary dictionary.

V - the total sum of words in the dictionary.





When the probabilities are calculated, the actual list of words is grouped by the most likely word from the created candidates.


We will need a dictionary to develop an autocorrect system where the smartphone uses history to match the typed words to see if they are correct or not.


To do this, we start by installing all the libraries general to machine learning from the terminal.


We import all the necessary libraries and packages to read the text file containing a vocabulary dictionary


As we have seen, NLP plays a crucial role in enabling computers to understand and process natural human language. This is as implemented above using the autocorrect
system. By referring to these detailed steps, we are able to comprehend the role of NLP for the design and implementation of our 
Autocorrect Model. 





-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Steps:

In the following lines, we will demonstrate the fundamental foundation of the functioning of our algorithm and our procedures.




To begin, we would need to import the neccessary libraries:
 
- Pandas
- Numpy
- sklearn
- GaussianNB


After this, we obtian a suitable data set to train and test our model. Through extensive research, we were able to come up with a file including 1001 of the most popular words used by individuals today. 
This set would be enough for a wide range of vocabulary.

Next we need to implement functions to edit our given word, these include 4 main functinons:

-'SwitchLetter' (Swaps to adajacent Character)
-'Replace_letter' (Replaces one Character for another)
-'Insert_Letter' (Adds additional Character)
-'Delete_Letter' (Deletes a character)

Then we need to combine the functions and alow the Model to switch between the functions if needed.



